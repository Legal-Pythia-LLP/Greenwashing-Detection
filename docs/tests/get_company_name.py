from wikirate4py import API
from pprint import pprint
import pandas as pd
from name_matching.name_matcher import NameMatcher
import time
import csv
import re
import multiprocessing

api = API("JoDaOQXoU2vzgRAbaArQlwtt")
# company = api.get_company("KPMG UNITED KINGDOM PLC")

# all_companies = []
# limit = 100
# offset = 0

# # while True:
# #     batch = api.get_companies(limit=limit, offset=offset)
# #     if not batch:
# #         break
# #     all_companies.extend(batch)

# #     print(f"âœ… æŠ“å–ä¸­: ç´¯è¨ˆ {len(all_companies)} å®¶å…¬å¸")
# #     if len(batch) < limit:
# #         break

# #     offset += limit
# #     time.sleep(0.2)  # å»ºè­°å°å»¶é²é¿å…éå¿«è¢«APIé™åˆ¶

# companies = api.get_companies(limit=100, offset=0)
# print(f"âœ… å·²ç²å¾— {len(companies)} å®¶å…¬å¸è³‡æ–™")

# # print("ğŸ“‹ å–å¾—å…¬å¸æ¸…å–®ï¼š")
# # for c in companies:
# #     print(c)

# # if companies:
# #     print("ç¬¬ä¸€å®¶å…¬å¸ç¯„ä¾‹ï¼š", companies[0])
# # else:
# #     print("âŒ æ²’æœ‰ä»»ä½•å…¬å¸è¢«å›å‚³")



# # å°‡çµæœå¯«å…¥ CSV æª”æ¡ˆ
# with open("wikirate_companies.csv", "w", newline="", encoding="utf-8") as csvfile:
#     writer = csv.writer(csvfile)
#     writer.writerow(["id", "name"])  # å¯«å…¥æ¬„ä½åç¨±
#     for i, company in enumerate(companies, start=1):
#         writer.writerow([str(company.id), str(company.name)])
#         print(f"type(company.id): {type(company.id)}")
#         print(f"type(company.name): {type(company.name)}")
#         print(f"ğŸ“ å¯«å…¥ç¬¬ {i} ç­†ï¼š{company.name}")


# print("ğŸ“ å…¬å¸åç¨±å·²å¯«å…¥ wikirate_companies.csv âœ…")

# æŠ“å…¨éƒ¨
# all_companies = []
# limit = 100
# offset = 0
# total_fetched = 0

# print("ğŸš€ é–‹å§‹æŠ“å–æ‰€æœ‰å…¬å¸è³‡æ–™...")

# while True:
#     batch = api.get_companies(limit=limit, offset=offset)
#     if not batch:
#         break

#     all_companies.extend(batch)
#     total_fetched += len(batch)

#     print(f"âœ… å·²æŠ“å– {total_fetched} å®¶å…¬å¸...")

#     if len(batch) < limit:
#         print("âœ… å·²æŠ“å–åˆ°æœ€å¾Œä¸€é ")
#         break

#     offset += limit
#     time.sleep(0.01)  # åŠ å°å»¶é²ä»¥é˜² API rate limit

# print(f"\nğŸ“¦ å…±å–å¾— {len(all_companies)} å®¶å…¬å¸è³‡æ–™ï¼Œæº–å‚™å¯«å…¥ CSV...")

# # å¯«å…¥ CSV
# with open("wikirate_companies_all.csv", "w", newline="", encoding="utf-8") as csvfile:
#     writer = csv.writer(csvfile)
#     writer.writerow(["id", "name"])
#     for i, company in enumerate(all_companies, start=1):
#         writer.writerow([str(company.id), str(company.name)])
#         if i % 500 == 0:
#             print(f"ğŸ“ å¯«å…¥ç¬¬ {i} ç­†ï¼š{company.name}")

# print("ğŸ“ å…¬å¸åç¨±å·²å®Œæ•´å¯«å…¥ wikirate_companies_all.csv âœ…")

# ============================================================================================================

# æŠ“2000
# all_companies = []
# limit = 100
# max_total = 2000  # è¦æŠ“å¹¾ç­†è³‡æ–™
# offset = 0

# with open("wikirate_companies_2000.csv", "w", newline="", encoding="utf-8") as csvfile:
#     writer = csv.writer(csvfile)
#     writer.writerow(["id", "name"])  # å¯«å…¥è¡¨é ­æ¬„ä½

#     while len(all_companies) < max_total:
#         companies = api.get_companies(limit=limit, offset=offset)

#         if not companies:
#             print("âŒ æ²’æœ‰æ›´å¤šå…¬å¸è³‡æ–™äº†ï¼Œæå‰çµæŸ")
#             break

#         all_companies.extend(companies)

#         for company in companies:
#             writer.writerow([str(company.id), str(company.name)])

#         print(f"âœ… ç¬¬ {offset // limit + 1} é ï¼Œå…± {len(all_companies)} ç­†")

#         offset += limit

# print("ğŸ“ å…¬å¸åç¨±å·²å¯«å…¥ wikirate_companies_2000.csv âœ…")

# ============================================================================================================
# æ‰¹é‡æŠ“2000

# search_names = ["Apple", "Puma", "HSBC", "KPMG", "JP Morgan"]

# company = api.get_company("Apple Inc.")
# if not company:
#     print("âŒ å…¬å¸æœªæ‰¾åˆ°")
#     exit()
# else:
#     print(company)

# all_companies = []
# total_target = 2000
# page_size = 100  # æ¯é æœ€å¤šå¯æŠ“100ç­†
# pages_per_round = 5  # æ¯è¼ªæŠ“å¹¾é ï¼ˆä¸€æ¬¡æœ€å¤š500ç­†ï¼‰
# offset = 0

# with open("wikirate_companies_2000.csv", "w", newline="", encoding="utf-8") as csvfile:
#     writer = csv.writer(csvfile)
#     writer.writerow(["id", "name"])  # å¯«å…¥è¡¨é ­

#     while len(all_companies) < total_target:
#         batch_companies = []

#         for i in range(pages_per_round):
#             if len(all_companies) + len(batch_companies) >= total_target:
#                 break

#             companies = api.get_companies(limit=page_size, offset=offset)
#             if not companies:
#                 print("âŒ æ²’æœ‰æ›´å¤šå…¬å¸è³‡æ–™äº†ï¼Œæå‰çµæŸ")
#                 break

#             batch_companies.extend(companies)
#             offset += page_size
#             print(f"ğŸ“¥ å·²æŠ“ç¬¬ {offset // page_size} é ï¼ˆ+{len(companies)} ç­†ï¼‰")

#         # å¯«å…¥ CSV
#         for company in batch_companies:
#             writer.writerow([str(company.id), str(company.name)])

#         all_companies.extend(batch_companies)
#         print(f"âœ… ç´¯è¨ˆ {len(all_companies)} ç­†è³‡æ–™")

# print("ğŸ“ å…¬å¸åç¨±å·²å¯«å…¥ wikirate_companies_2000.csv âœ…")

# ============================================================================================================


# search_names = ["Apple", "Puma", "HSBC", "KPMG", "JP Morgan"]

# company = api.get_company("Apple Inc.")
# if not company:
#     print("âŒ å…¬å¸æœªæ‰¾åˆ°")
#     exit()
# else:
#     print(company)

# æ¸¬è©¦æŠ“ ISIN æ•¸é‡
# def get_isin_count(company):
#     """ç›´æ¥æ¥æ”¶ company ç‰©ä»¶ï¼Œå›å‚³ ISIN æ•¸é‡"""
#     try:
#         isin_list = company.isin if hasattr(company, "isin") else []
#         isin_count = len(isin_list)

#         print(f"ğŸ†” ID: {company.id}")
#         print(f"ğŸ·ï¸ Name: {company.name}")
#         print(f"111ğŸ”¢ ISIN æ•¸é‡: {isin_count}")
#         return isin_count

#     except Exception as e:
#         print(f"âš ï¸ ç„¡æ³•è™•ç†å…¬å¸ {company}: {e}")
#         return 0

# def get_isin_count_by_id_or_name(company_id_or_name):
#     try:
#         company = api.get_company(company_id_or_name)
#         if not company:
#             print(f"âŒ æ‰¾ä¸åˆ°å…¬å¸: {company_id_or_name}")
#             return 0
#         return get_isin_count(company)
#     except Exception as e:
#         print(f"âš ï¸ ç„¡æ³•å–å¾—å…¬å¸ {company_id_or_name} çš„ ISIN æ•¸é‡: {e}")
#         return 0

# # ğŸ” æŒ‡å®šå…¬å¸ ID æ¸¬è©¦
# target_company_id = 637  # Apple Inc.
# company = api.get_company(target_company_id)
# if not company:
#     print("âŒ æ‰¾ä¸åˆ°å…¬å¸")
# else:
#     isin_count = get_isin_count(company)




# ğŸ” æŒ‡å®šå…¬å¸ ID æ¸¬è©¦
# target_company_id = 637  # ğŸ‘ˆ ä½ å¯ä»¥æ”¹æˆä»»ä½•ä¸€é–“å…¬å¸çš„ IDï¼ˆä¾‹å¦‚ Apple æ˜¯ 1578ï¼‰
# company = api.get_company(target_company_id)

# print(f"ğŸ†” ID: {company.id}")
# print(f"ğŸ·ï¸ Name: {company.name}")
# print(f"ğŸ”¢ ISIN æ•¸é‡: {isin_count}")

# ============================================================================================================

# æŠ“2000 ä¸¦ä¸”æŠ“ ISIN æ•¸é‡


# all_companies = []
# total_target = 300
# page_size = 100  # æ¯é æœ€å¤šå¯æŠ“100ç­†
# pages_per_round = 5  # æ¯è¼ªæŠ“å¹¾é ï¼ˆä¸€æ¬¡æœ€å¤š500ç­†ï¼‰
# offset = 0

# def get_isin_count(company):
#     """ç›´æ¥å¾å…¬å¸ç‰©ä»¶ä¸­è®€å– ISIN æ•¸é‡"""
#     try:
#         isin = getattr(company, "isin", None)
#         isin_list = isin if isinstance(isin, list) else []
#         isin_count = len(isin_list)

#         print(f"ğŸ†” ID: {company.id}")
#         print(f"ğŸ·ï¸ Name: {company.name}")
#         print(f"ğŸ”¢ ISIN æ•¸é‡: {isin_count}")
#         return isin_count

#     except Exception as e:
#         print(f"âš ï¸ ç„¡æ³•è™•ç†å…¬å¸ {company}: {e}")
#         return 0

# with open("wikirate_companies_2000.csv", "w", newline="", encoding="utf-8") as csvfile:
#     writer = csv.writer(csvfile)
#     writer.writerow(["id", "name", "isin_count"])  # å¯«å…¥è¡¨é ­

#     # while len(all_companies) < total_target: //çœ‹è¦æŠ“å¤šå°‘
#     while True: # ç„¡é™æŠ“
#         batch_companies = []

#         for i in range(pages_per_round):
#             # if len(all_companies) + len(batch_companies) >= total_target:
#             #     break

#             companies = api.get_companies(limit=page_size, offset=offset)
#             if not companies:
#                 print("âŒ æ²’æœ‰æ›´å¤šå…¬å¸è³‡æ–™äº†ï¼Œæå‰çµæŸ")
#                 break

#             for company in companies:
#                 isin_count = get_isin_count(company)  # âœ… æ”¹æˆç›´æ¥å‚³ company
#                 writer.writerow([str(company.id), str(company.name), isin_count])
#                 time.sleep(0.2)  # æ§åˆ¶é€Ÿåº¦é¿å… API é™åˆ¶

#             batch_companies.extend(companies)
#             offset += page_size
#             print(f"ğŸ“¥ å·²æŠ“ç¬¬ {offset // page_size} é ï¼ˆ+{len(companies)} ç­†ï¼‰")

#         all_companies.extend(batch_companies)
#         print(f"âœ… ç´¯è¨ˆ {len(all_companies)} ç­†è³‡æ–™")

# print("ğŸ“ å…¬å¸åç¨±èˆ‡ ISIN æ•¸é‡å·²å¯«å…¥ wikirate_companies_2000.csv âœ…")

# ============================================================================================================
# # å¤šç·šç¨‹æŠ“ company id, company name, ISIN æ•¸é‡
# PAGE_SIZE = 100
# MAX_PAGES = 100000  # é ä¼°æœ€å¤šæŠ“å¹¾é ï¼Œç„¡è³‡æ–™æ™‚æœƒè‡ªå‹•åœæ­¢
# OUTPUT_FILE = "wikirate_companies_all.csv"  # âœ… ä½ è¦çš„æª”å

# def get_isin_count(company):
#     """å¾å…¬å¸ç‰©ä»¶ä¸­è®€å– ISIN æ•¸é‡"""
#     try:
#         isin = getattr(company, "isin", None)
#         isin_list = isin if isinstance(isin, list) else []
#         return len(isin_list)
#     except Exception as e:
#         print(f"âš ï¸ ç„¡æ³•è™•ç†å…¬å¸ {company}: {e}")
#         return 0

# def worker(task_queue, result_queue, worker_id):
#     """æ¯å€‹é€²ç¨‹æŠ“å–æŒ‡å®š offset é çš„è³‡æ–™"""
#     while True:
#         try:
#             offset = task_queue.get(timeout=2)
#         except:
#             break  # æ²’æœ‰æ–°å·¥ä½œå°±é€€å‡º

#         companies = api.get_companies(limit=PAGE_SIZE, offset=offset)
#         if not companies:
#             print(f"ğŸš« Worker {worker_id} - offset {offset} æ²’æœ‰è³‡æ–™ï¼Œåœæ­¢")
#             break

#         results = []
#         for company in companies:
#             isin_count = get_isin_count(company)
#             results.append((str(company.id), str(company.name), isin_count))

#         for row in results:
#             result_queue.put(row)

#         print(f"âœ… Worker {worker_id} - æŠ“å– offset {offset} å…± {len(companies)} ç­†")
#         time.sleep(0.2)  # æ§åˆ¶é€Ÿåº¦é¿å… API é™åˆ¶

# def parallel_fetch(num_workers=6):
#     manager = multiprocessing.Manager()
#     task_queue = manager.Queue()
#     result_queue = manager.Queue()

#     # å‹•æ…‹ç”¢ç”Ÿ offset ä»»å‹™
#     for i in range(MAX_PAGES):
#         task_queue.put(i * PAGE_SIZE)

#     # å»ºç«‹å¤šå€‹é€²ç¨‹
#     processes = []
#     for i in range(num_workers):
#         p = multiprocessing.Process(target=worker, args=(task_queue, result_queue, i))
#         p.start()
#         processes.append(p)

#     # ç­‰å¾…å…¨éƒ¨å®Œæˆ
#     for p in processes:
#         p.join()

#     print("ğŸ“ æ‰€æœ‰ worker å®Œæˆï¼Œæº–å‚™å¯«å…¥æª”æ¡ˆ...")

#     # å¯«å…¥ CSV çµæœ
#     with open(OUTPUT_FILE, "w", newline="", encoding="utf-8") as csvfile:
#         writer = csv.writer(csvfile)
#         writer.writerow(["id", "name", "isin_count"])
#         while not result_queue.empty():
#             writer.writerow(result_queue.get())

#     print(f"ğŸ“ å·²å¯«å…¥ {OUTPUT_FILE}")

# # âœ… åŸ·è¡Œä¸»ç¨‹å¼
# if __name__ == "__main__":
#     parallel_fetch(num_workers=6)

# ============================================================================================================

# åå­—æ¨¡ç³Šæ¯”å°
# âœ… è‡ªè¨‚ normalization æ–¹æ³•ï¼ˆæ¨¡ä»¿ NameMatcher transform=Trueï¼‰
def normalize_name(name: str) -> str:
    name = name.lower()
    name = re.sub(r'[^a-z0-9\s]', '', name)   # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
    name = re.sub(r'\s+', ' ', name)          # ç§»é™¤å¤šé¤˜ç©ºç™½
    return name.strip()


# âœ… ä¸»å‡½æ•¸ï¼šæ ¹æ“šè¼¸å…¥åç¨±æ¨¡ç³Šæ¯”å°ï¼Œä¸¦æ ¹æ“š ISIN æ•¸é‡é¸æ“‡æœ€ä½³åŒ¹é…
def find_best_matching_company(input_name: str, wikirate_companies: list) -> str:
    
    keyword = input_name.lower()
    filtered_companies = [c for c in wikirate_companies if keyword in c['name'].lower()]
    if not filtered_companies:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½•åç¨±åŒ…å«é—œéµå­—çš„å…¬å¸")
        return None

    # âœ… å°å‡ºæ‰€æœ‰ç¬¦åˆæ¢ä»¶çš„å…¬å¸åç¨±
    print("ğŸ” æ‰¾åˆ°ä»¥ä¸‹åŒ…å«é—œéµå­—çš„å…¬å¸ï¼š")
    for c in filtered_companies:
        print(f" - {c['name']}")

    company_names = [c['name'] for c in filtered_companies]

    # å»ºç«‹è½‰æ›å°ç…§è¡¨
    normalized_map = {}
    for c in wikirate_companies:
        original_name = c['name'] if isinstance(c, dict) else c
        normalized = normalize_name(original_name)
        normalized_map[normalized] = {
            'original_name': original_name,
            'isin_count': c.get('isin_count', 0) if isinstance(c, dict) else 0
        }

    df_master = pd.DataFrame({'Company name': company_names})
    df_input = pd.DataFrame({'name': [input_name]})

    matcher = NameMatcher(
        number_of_matches=5,
        legal_suffixes=True,
        common_words=False,
        top_n=50,
        verbose=False
    )
    matcher.set_distance_metrics(['bag', 'typo', 'refined_soundex'])
    matcher.load_and_process_master_data(column='Company name', df_matching_data=df_master, transform=True)
    matches = matcher.match_names(to_be_matched=df_input, column_matching='name')

    if matches.empty:
        return None

    # ğŸ§ª å°å‡ºæ‰€æœ‰åŒ¹é…çš„åç¨±èˆ‡åˆ†æ•¸
    print("ğŸ§ª æ‰€æœ‰åŒ¹é…çµæœï¼š")
    results = []
    for i in range(5):
        match_name_col = f'match_name_{i}'
        score_col = f'score_{i}'
        if match_name_col in matches.columns and score_col in matches.columns:
            match_name = matches.at[0, match_name_col]
            score = matches.at[0, score_col]
            if pd.notna(match_name):
                normalized = normalize_name(match_name)
                isin_count = normalized_map.get(normalized, {}).get('isin_count', 0)
                print(f"{i+1}. {match_name}  ğŸ‘‰ åˆ†æ•¸: {score:.2f}  ğŸ†” ISINæ•¸é‡: {isin_count}")
                results.append((normalized, score))

    if not results:
        return None

    # æ‰¾å‡ºæœ€é«˜åˆ†
    max_score = max(score for _, score in results)
    top_matches = [name for name, score in results if score == max_score]

    # å¦‚æœåªæœ‰ä¸€å€‹æœ€é«˜åˆ† â†’ å›å‚³åŸå§‹åç¨±
    if len(top_matches) == 1:
        return normalized_map.get(top_matches[0], {}).get('original_name', top_matches[0])

    # å¦‚æœæœ‰å¤šå€‹æœ€é«˜åˆ† â†’ ç”¨ isin_count æŒ‘é¸
    best_match = max(top_matches, key=lambda name: normalized_map.get(name, {}).get('isin_count', 0))
    return normalized_map.get(best_match, {}).get('original_name', best_match)

# ============================================================================================================
# # test
# input_name = "Apple Inc"
# company_list = ["Apple Inc.", "Apple AB", "APPLE PTY LIMITED", "APPLE EUROPE LIMITED", "APPLE APPAREL (CAMBODIA) CO., LTD"]

# best_match = find_best_matching_company(input_name, company_list)
# print("ğŸ” æœ€ä½³åŒ¹é…çµæœ:", best_match)

# æ¸¬è©¦åƒæ•¸
input_name = "apple"
csv_path = "wikirate_companies_all.csv"

# è®€å– CSV
df = pd.read_csv(csv_path)

# ç¢ºä¿æ¬„ä½å­˜åœ¨
if "name" not in df.columns or "isin_count" not in df.columns:
    raise ValueError("CSV æª”æ¡ˆä¸­éœ€è¦åŒ…å« 'name' å’Œ 'isin_count' æ¬„ä½")

# æº–å‚™æˆ list of dict çµæ§‹
wikirate_companies = df[["name", "isin_count"]].to_dict(orient="records")

# åŸ·è¡ŒåŒ¹é…å‡½æ•¸
best_match = find_best_matching_company(input_name, wikirate_companies)

# è¼¸å‡ºçµæœ
print(f"\nğŸ“Œ å°æ–¼è¼¸å…¥ '{input_name}'ï¼Œæœ€ä½³åŒ¹é…å…¬å¸åç¨±ç‚ºï¼š{best_match}")

# ============================================================================================================
# # æ¨¡æ“¬ csv ä¸­çš„å…¬å¸è³‡æ–™
# wikirate_companies = [
#     {"id": 637, "name": "BP plc.", "isin_count": 117},
#     {"id": 932, "name": "Chevron Corporation", "isin_count": 1},
#     {"id": 993, "name": "Shell plc", "isin_count": 1},
#     {"id": 1578, "name": "Apple Inc.", "isin_count": 1004},       # âœ… æ‡‰è©²é¸é€™å€‹
#     {"id": 1102, "name": "Apple AB", "isin_count": 20},
#     {"id": 1103, "name": "Apple AInc", "isin_count": 100}
# ]

# input_name = "apple"
# result = find_best_matching_company(input_name, wikirate_companies)

# print(f"\nğŸ“Œ æ¸¬è©¦çµæœï¼šè¼¸å…¥ã€{input_name}ã€ï¼ŒåŒ¹é…åˆ°ï¼š{result}")






